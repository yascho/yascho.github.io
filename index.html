<!doctype html>
<html lang="en">
  <head>
	<meta charset="utf-8" />
	<meta http-equiv="x-ua-compatible" content="ie=edge" />
	<meta name="viewport" content="width=device-width, initial-scale=1" />
      
	<title>
	  Yan Scholten
	</title>

	<!-- Begin Jekyll SEO tag v2.7.1 -->
<meta name="generator" content="Jekyll v4.2.1" />
<meta property="og:title" content="Yan Scholten" />
<meta name="author" content="Yan Scholten" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Master&#39;s student in Informatics at the Technical University of Munich" />
<meta property="og:description" content="Master&#39;s student in Informatics at the Technical University of Munich" />
<link rel="canonical" href="https://yascho.github.io" />
<meta property="og:url" content="https://yascho.github.io" />
<meta property="og:site_name" content="Yan Scholten" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="Yan Scholten" />
<meta name="twitter:site" content="@YanScholten" />
<meta name="twitter:creator" content="@Yan Scholten" />
<script type="application/ld+json">
{"name":"Yan Scholten","author":{"@type":"Person","name":"Yan Scholten"},"url":"https://yascho.github.io","@type":"WebSite","description":"Master&#39;s student in Informatics at the Technical University of Munich","headline":"Yan Scholten","dateModified":"2024-12-23T23:01:41+01:00","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

	<meta name="google-site-verification" content="chbllHIfU7hyPiWimLppN2ds-jk7A3FxoRpNI2xsg8Q" />
      
	<link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-1BmE4kWBq78iYhFldvKuhfTAU6auU8tT94WrHftjDbrCEXSU1oBoqyl2QvZ6jIW3" crossorigin="anonymous">
	<link rel="stylesheet" href="/css/main.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap-icons@1.6.1/font/bootstrap-icons.css">
	<link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
	<link
	  href="https://fonts.googleapis.com/css?family=Open+Sans:400,300,700,800,600"
	  rel="stylesheet"
	  type="text/css"
	/>
	<link
	  href="https://fonts.googleapis.com/css?family=Muli:400,300"
	  rel="stylesheet"
	  type="text/css"
	/>
</head>
  <body class="d-flex flex-column h-100">
    <aside class="navbar-fixed-top navbar navbar-expand-lg navbar-light">
	<nav class="container row p-0">
		<div class="col ps-sm-2 ps-md-0">
			<div class="p-0">
				
					<a href="https://www.cs.cit.tum.de/daml/team/yan-scholten/" target="_blank" rel="noopener noreferrer"><i class="bi bi-briefcase-fill"></i></a>
					<a href="https://github.com/yascho" target="_blank" rel="noopener noreferrer"><i class="bi bi-github"></i></a>
					<!--<a href="https://twitter.com/YanScholten" target="_blank" rel="noopener noreferrer"><i class="bi bi-twitter"></i></a>-->
					<!-- <a rel="me" href="https://sigmoid.social/@yanscholten"><i class="bi bi-mastodon"></i></a> -->
					<a href="https://scholar.google.com/citations?hl=en&user=8G2bJ7sAAAAJ&sortby=pubdate" target="_blank" rel="noopener noreferrer"><i class="ai ai-google-scholar"></i></a>
				
			</div>
		</div>
		<div class="col-auto m-0 p-0">
			<!-- future responsive navbar button 
			<button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
			<span class="navbar-toggler-icon"></span>
			</button>
			<div class="collapse navbar-collapse" id="navbarNav">-->
			<!--<h2 class="mt-5 pb-1">Yan Scholten</h2>-->
			<ul class="p-0 m-0">
				<ul class="navbar-nav">
				 
				<!--<li class="nav-item"><a aria-current="page" href="/">Home</a></li> -->
					
      					<li class="nav-item"><a aria-current="page" href="/" class="active">Home</a></li>
    				
				  
				<!--<li class="nav-item"><a aria-current="page" href="/">Home</a></li> -->
					
						<li class="nav-item"><a aria-current="page" href="/publications">Publications</a></li>
    				
				       
				<!--<li><a href="/blog">Blog</a></li>-->
			</ul>
			<!--</div>-->
		</div>
	</nav>
</aside>
    <main class="container flex-shrink-0 p-0">
      <article class="container"><!--
<div class="container row p-0 m-0">
	<div class="col">
		<h1 class="mt-5 pb-1"><a href="/">Yan Scholten</a></h1>
		<div class="p-0 text-muted authors">PhD student in Computer Science, Technical University of Munich</div>
	</div>
	<div class="col-auto">
		<img src="/assets/yan-scholten.jpg" id="me" class="float-md-end mb-3 ms-md-3 mt-1" alt="Yan Scholten">
	</div>
</div>
-->

<h2 class="mt-5 pb-1">Yan Scholten</h2>
<div class="container clearfix pe-0 ps-0 ps-md-3 force-justify">
	<img src="/assets/yan-scholten.jpg" id="me" class="img-fluid float-md-end mb-3 ms-md-3 mt-2 d-none d-md-block d-xl-block" alt="Yan Scholten" />
	<p>
	Hey ðŸ‘‹ I am a PhD student in the 
	<a href="https://www.cs.cit.tum.de/en/daml/home/" target="_blank" rel="noopener noreferrer">Data Analytics and Machine Learning</a> group at the <a href="https://www.cit.tum.de/en/cit/home/" target="_blank" rel="noopener noreferrer">Technical University of Munich (TUM)</a> located in Munich ðŸ‡©ðŸ‡ª, supervised by <a href="https://www.cs.cit.tum.de/en/daml/team/damlguennemann/" target="_blank" rel="noopener noreferrer">Prof. Stephan GÃ¼nnemann</a>.<br />
	My research focuses on enhancing the reliability and safety of machine learning.
	My broader research interests include <strong>adversarial robustness</strong>, <strong>robustness certification</strong>, <strong>conformal prediction</strong>, <strong>uncertainty quantification</strong>, <strong>machine unlearning, alignment</strong>, <strong>large language models (LLMs)</strong>, and <strong>machine learning for graphs</strong>.<br />
	I further enjoy traveling, language learning, swimming and dancing. 
	Feel free to reach out! ðŸ˜Š
	</p>

</div>

<h2 class="mt-5 pb-1 text-left">Selected Publications (<a href="/publications">full list</a>)</h2>

<div class="container pe-0 ps-0 ps-md-3">
	<ol class="bibliography"><li><div class="container mt-2 mb-3 ps-0 pe-0">
<a class="title" href="https://arxiv.org/pdf/2410.03523">A Probabilistic Perspective on Unlearning and Alignment for Large Language Models</a>
<br />
<div class="container authors p-0">

	
		<b>Yan Scholten</b>,
	

	
		Stephan GÃ¼nnemann,
	

	
		and Leo Schwinn
	

<br />
<span class="font-italic">arXiv preprint</span>,  2024.
</div>
<div class="btn-group pt-1 flex-wrap" role="group">
	
	<a class="btn btn-primary btn-sm collapsed" role="button" data-bs-toggle="collapse" data-bs-target="#scholten2024probabilistic" aria-expanded="false" aria-controls="scholten2024probabilistic">Abs</a>
	
	
		<a role="button" href="https://arxiv.org/abs/2410.03523" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Web</a>
	
	
		<a role="button" href="https://arxiv.org/pdf/2410.03523" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">PDF</a>
	
	
	
	
	
		<a role="button" href="https://github.com/yascho/probabilistic-unlearning" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Code</a>
	
	
	<a role="button" onclick="var txt=`@inproceedings{scholten2024probabilistic,
  author = {Scholten, Yan and GÃ¼nnemann, Stephan and Schwinn, Leo},
  title = {A Probabilistic Perspective on Unlearning and Alignment for Large Language Models},
  booktitle = {arXiv preprint},
  year = {2024},
  web = {https://arxiv.org/abs/2410.03523},
  pdf = {https://arxiv.org/pdf/2410.03523},
  code = {https://github.com/yascho/probabilistic-unlearning},
  abs = {Comprehensive evaluation of Large Language Models (LLMs) is an open research problem. Existing evaluations rely on deterministic point estimates generated via greedy decoding. However, we find that deterministic evaluations fail to capture the whole output distribution of a model, yielding inaccurate estimations of model capabilities. This is particularly problematic in critical contexts such as unlearning and alignment, where precise model evaluations are crucial. To remedy this, we introduce the first formal probabilistic evaluation framework in LLMs. Namely, we derive novel metrics with high-probability guarantees concerning the output distribution of a model. Our metrics are application-independent and allow practitioners to make more reliable estimates about model capabilities before deployment. Through a case study focused on unlearning, we reveal that deterministic evaluations falsely indicate successful unlearning, whereas our probabilistic evaluations demonstrate that most if not all of the supposedly unlearned information remains accessible in these models. Additionally, we propose a novel unlearning loss based on entropy optimization and adaptive temperature scaling, which significantly improves unlearning in probabilistic settings on recent benchmarks. Our proposed shift from point estimates to probabilistic evaluations of output distributions represents an important step toward comprehensive evaluations of LLMs.}
}
`; copy(txt)" class="btn btn-primary btn-sm collapsed" data-toggle="tooltip" data-delay="{&quot;show&quot;:&quot;500&quot;}" data-placement="top" title="Copied!">BibTeX</a>
	
</div>
<div class="collapse mt-1 p-0" id="scholten2024probabilistic">
	<div class="card card-body">
		Comprehensive evaluation of Large Language Models (LLMs) is an open research problem. Existing evaluations rely on deterministic point estimates generated via greedy decoding. However, we find that deterministic evaluations fail to capture the whole output distribution of a model, yielding inaccurate estimations of model capabilities. This is particularly problematic in critical contexts such as unlearning and alignment, where precise model evaluations are crucial. To remedy this, we introduce the first formal probabilistic evaluation framework in LLMs. Namely, we derive novel metrics with high-probability guarantees concerning the output distribution of a model. Our metrics are application-independent and allow practitioners to make more reliable estimates about model capabilities before deployment. Through a case study focused on unlearning, we reveal that deterministic evaluations falsely indicate successful unlearning, whereas our probabilistic evaluations demonstrate that most if not all of the supposedly unlearned information remains accessible in these models. Additionally, we propose a novel unlearning loss based on entropy optimization and adaptive temperature scaling, which significantly improves unlearning in probabilistic settings on recent benchmarks. Our proposed shift from point estimates to probabilistic evaluations of output distributions represents an important step toward comprehensive evaluations of LLMs.
	</div>
</div>
</div></li>
<li><div class="container mt-2 mb-3 ps-0 pe-0">
<a class="title" href="https://yascho.github.io/assets/pdf/scholten2024provably.pdf">Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning</a>
<br />
<div class="container authors p-0">

	
		<b>Yan Scholten</b>,
	

	
		and Stephan GÃ¼nnemann
	

<br />
<span class="font-italic">arXiv preprint</span>,  2024.
</div>
<div class="btn-group pt-1 flex-wrap" role="group">
	
	<a class="btn btn-primary btn-sm collapsed" role="button" data-bs-toggle="collapse" data-bs-target="#scholten2024provably" aria-expanded="false" aria-controls="scholten2024provably">Abs</a>
	
	
		<a role="button" href="https://arxiv.org/abs/2410.09878" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Web</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2024provably.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">PDF</a>
	
	
	
	
	
	
	<a role="button" onclick="var txt=`@inproceedings{scholten2024provably,
  author = {Scholten, Yan and GÃ¼nnemann, Stephan},
  title = {Provably Reliable Conformal Prediction Sets in the Presence of Data Poisoning},
  booktitle = {arXiv preprint},
  year = {2024},
  pdf = {https://yascho.github.io/assets/pdf/scholten2024provably.pdf},
  web = {https://arxiv.org/abs/2410.09878},
  abs = {Conformal prediction provides model-agnostic and distribution-free uncertainty quantification through prediction sets that are guaranteed to include the ground truth with any user-specified probability. Yet, conformal prediction is not reliable under poisoning attacks where adversaries manipulate both training and calibration data, which can significantly alter prediction sets in practice. As a solution, we propose reliable prediction sets (RPS): the first efficient method for constructing conformal prediction sets with provable reliability guarantees under poisoning. To ensure reliability under training poisoning, we introduce smoothed score functions that reliably aggregate predictions of classifiers trained on distinct partitions of the training data. To ensure reliability under calibration poisoning, we construct multiple prediction sets, each calibrated on distinct subsets of the calibration data. We then aggregate them into a majority prediction set, which includes a class only if it appears in a majority of the individual sets. Both proposed aggregations mitigate the influence of datapoints in the training and calibration data on the final prediction set. We experimentally validate our approach on image classification tasks, achieving strong reliability while maintaining utility and preserving coverage on clean data. Overall, our approach represents an important step towards more trustworthy uncertainty quantification in the presence of data poisoning.}
}
`; copy(txt)" class="btn btn-primary btn-sm collapsed" data-toggle="tooltip" data-delay="{&quot;show&quot;:&quot;500&quot;}" data-placement="top" title="Copied!">BibTeX</a>
	
</div>
<div class="collapse mt-1 p-0" id="scholten2024provably">
	<div class="card card-body">
		Conformal prediction provides model-agnostic and distribution-free uncertainty quantification through prediction sets that are guaranteed to include the ground truth with any user-specified probability. Yet, conformal prediction is not reliable under poisoning attacks where adversaries manipulate both training and calibration data, which can significantly alter prediction sets in practice. As a solution, we propose reliable prediction sets (RPS): the first efficient method for constructing conformal prediction sets with provable reliability guarantees under poisoning. To ensure reliability under training poisoning, we introduce smoothed score functions that reliably aggregate predictions of classifiers trained on distinct partitions of the training data. To ensure reliability under calibration poisoning, we construct multiple prediction sets, each calibrated on distinct subsets of the calibration data. We then aggregate them into a majority prediction set, which includes a class only if it appears in a majority of the individual sets. Both proposed aggregations mitigate the influence of datapoints in the training and calibration data on the final prediction set. We experimentally validate our approach on image classification tasks, achieving strong reliability while maintaining utility and preserving coverage on clean data. Overall, our approach represents an important step towards more trustworthy uncertainty quantification in the presence of data poisoning.
	</div>
</div>
</div></li>
<li><div class="container mt-2 mb-3 ps-0 pe-0">
<a class="title" href="https://yascho.github.io/assets/pdf/scholten2023hierarchical.pdf">Hierarchical Randomized Smoothing</a>
<br />
<div class="container authors p-0">

	
		<b>Yan Scholten</b>,
	

	
		Jan Schuchardt,
	

	
		Aleksandar Bojchevski,
	

	
		and Stephan GÃ¼nnemann
	

<br />
<span class="font-italic">Conference on Neural Information Processing Systems</span>, NeurIPS 2023.
</div>
<div class="btn-group pt-1 flex-wrap" role="group">
	
	<a class="btn btn-primary btn-sm collapsed" role="button" data-bs-toggle="collapse" data-bs-target="#scholten2023hierarchical" aria-expanded="false" aria-controls="scholten2023hierarchical">Abs</a>
	
	
		<a role="button" href="https://www.cs.cit.tum.de/daml/hierarchical-smoothing/" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Web</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2023hierarchical.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">PDF</a>
	
	
		<a role="button" href="https://nips.cc/virtual/2023/poster/72764" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Talk</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2023hierarchical-slides.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Slides</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2023hierarchical-poster.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Poster</a>
	
	
		<a role="button" href="https://github.com/yascho/hierarchical_smoothing" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Code</a>
	
	
	<a role="button" onclick="var txt=`@inproceedings{scholten2023hierarchical,
  author = {Scholten, Yan and Schuchardt, Jan and Bojchevski, Aleksandar and GÃ¼nnemann, Stephan},
  title = {Hierarchical Randomized Smoothing},
  booktitle = {Conference on Neural Information Processing Systems},
  abbr = {NeurIPS},
  year = {2023},
  slides = {https://yascho.github.io/assets/pdf/scholten2023hierarchical-slides.pdf},
  web = {https://www.cs.cit.tum.de/daml/hierarchical-smoothing/},
  code = {https://github.com/yascho/hierarchical_smoothing},
  talk = {https://nips.cc/virtual/2023/poster/72764},
  pdf = {https://yascho.github.io/assets/pdf/scholten2023hierarchical.pdf},
  poster = {https://yascho.github.io/assets/pdf/scholten2023hierarchical-poster.pdf},
  abs = {Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs -- by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both -- certifiably robust to perturbations and accurate.}
}
`; copy(txt)" class="btn btn-primary btn-sm collapsed" data-toggle="tooltip" data-delay="{&quot;show&quot;:&quot;500&quot;}" data-placement="top" title="Copied!">BibTeX</a>
	
</div>
<div class="collapse mt-1 p-0" id="scholten2023hierarchical">
	<div class="card card-body">
		Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs â€“ by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both â€“ certifiably robust to perturbations and accurate.
	</div>
</div>
</div></li>
<li><div class="container mt-2 mb-3 ps-0 pe-0">
<a class="title" href="https://yascho.github.io/assets/pdf/scholten2022randomized.pdf">Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks</a>
<br />
<div class="container authors p-0">

	
		<b>Yan Scholten</b>,
	

	
		Jan Schuchardt,
	

	
		Simon Geisler,
	

	
		Aleksandar Bojchevski,
	

	
		and Stephan GÃ¼nnemann
	

<br />
<span class="font-italic">Conference on Neural Information Processing Systems</span>, NeurIPS 2022.
</div>
<div class="btn-group pt-1 flex-wrap" role="group">
	
	<a class="btn btn-primary btn-sm collapsed" role="button" data-bs-toggle="collapse" data-bs-target="#scholten2022randomized" aria-expanded="false" aria-controls="scholten2022randomized">Abs</a>
	
	
		<a role="button" href="https://www.cs.cit.tum.de/daml/interception-smoothing/" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Web</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2022randomized.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">PDF</a>
	
	
		<a role="button" href="https://www.youtube.com/watch?v=rbFiXrh9Snk" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Talk</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2022randomized-slides.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Slides</a>
	
	
		<a role="button" href="https://yascho.github.io/assets/pdf/scholten2022randomized-poster.pdf" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Poster</a>
	
	
		<a role="button" href="https://github.com/yascho/interception_smoothing" class="btn btn-primary btn-sm collapsed" target="_blank" rel="noopener noreferrer">Code</a>
	
	
	<a role="button" onclick="var txt=`@inproceedings{scholten2022randomized,
  author = {Scholten, Yan and Schuchardt, Jan and Geisler, Simon and Bojchevski, Aleksandar and GÃ¼nnemann, Stephan},
  title = {Randomized Message-Interception Smoothing: Gray-box Certificates for Graph Neural Networks},
  booktitle = {Conference on Neural Information Processing Systems},
  abbr = {NeurIPS},
  year = {2022},
  pdf = {https://yascho.github.io/assets/pdf/scholten2022randomized.pdf},
  talk = {https://www.youtube.com/watch?v=rbFiXrh9Snk},
  slides = {https://yascho.github.io/assets/pdf/scholten2022randomized-slides.pdf},
  poster = {https://yascho.github.io/assets/pdf/scholten2022randomized-poster.pdf},
  code = {https://github.com/yascho/interception_smoothing},
  web = {https://www.cs.cit.tum.de/daml/interception-smoothing/},
  abs = {Randomized smoothing is one of the most promising frameworks for certifying the adversarial robustness of machine learning models, including Graph Neural Networks (GNNs). Yet, existing randomized smoothing certificates for GNNs are overly pessimistic since they treat the model as a black box, ignoring the underlying architecture. To remedy this, we propose novel gray-box certificates that exploit the message-passing principle of GNNs: We randomly intercept messages and carefully analyze the probability that messages from adversarially controlled nodes reach their target nodes. Compared to existing certificates, we certify robustness to much stronger adversaries that control entire nodes in the graph and can arbitrarily manipulate node features. Our certificates provide stronger guarantees for attacks at larger distances, as messages from farther-away nodes are more likely to get intercepted. We demonstrate the effectiveness of our method on various models and datasets. Since our gray-box certificates consider the underlying graph structure, we can significantly improve certifiable robustness by applying graph sparsification.}
}
`; copy(txt)" class="btn btn-primary btn-sm collapsed" data-toggle="tooltip" data-delay="{&quot;show&quot;:&quot;500&quot;}" data-placement="top" title="Copied!">BibTeX</a>
	
</div>
<div class="collapse mt-1 p-0" id="scholten2022randomized">
	<div class="card card-body">
		Randomized smoothing is one of the most promising frameworks for certifying the adversarial robustness of machine learning models, including Graph Neural Networks (GNNs). Yet, existing randomized smoothing certificates for GNNs are overly pessimistic since they treat the model as a black box, ignoring the underlying architecture. To remedy this, we propose novel gray-box certificates that exploit the message-passing principle of GNNs: We randomly intercept messages and carefully analyze the probability that messages from adversarially controlled nodes reach their target nodes. Compared to existing certificates, we certify robustness to much stronger adversaries that control entire nodes in the graph and can arbitrarily manipulate node features. Our certificates provide stronger guarantees for attacks at larger distances, as messages from farther-away nodes are more likely to get intercepted. We demonstrate the effectiveness of our method on various models and datasets. Since our gray-box certificates consider the underlying graph structure, we can significantly improve certifiable robustness by applying graph sparsification.
	</div>
</div>
</div></li></ol>
</div>

<h2 class="mt-5 pb-1">Education</h2>
<div class="container clearfix pe-0 ps-0 ps-md-3 force-justify">
<ul style=" padding-left: 0;">
    	<li><strong>2022-now</strong>: PhD student in Computer Science, Technical University of Munich</li>
    	<li><strong>2019-2022</strong>: M.Sc. Informatics, Technical University of Munich (with high distinction)</li>
    	<li><strong>2015-2019</strong>: B.Sc. Computer Science (Math Minor), Paderborn University (with distinction)</li>
</ul>
</div>

<h2 class="mt-5 pb-1">Academic Honors and Awards</h2>
<div class="container clearfix pe-0 ps-0 ps-md-3 force-justify">
<ul style=" padding-left: 0;">
    <li><strong>2023</strong>: Admission to the Konrad Zuse School of Excellence in Reliable AI</li>
    <li><strong>2019</strong>: Deutschlandstipendium awarded by the Technical University of Munich</li>
    <li><strong>2018</strong>: RISE worldwide scholarship awarded by DAAD</li>
    <li><strong>2018</strong>: Deutschlandstipendium awarded by Studienfonds OWL</li>
	<li><strong>2017</strong>: Admission to elite program of the EIM-faculty at Paderborn University</li>
</ul>
</div>
</article>
    </main>
	  <footer class="footer m-auto mt-5 p-0">
	<div class="d-flex p-0">
		<div class="flex-fill text-start p-0">
			<span class="text-muted">Yan Scholten &copy; <script>document.write(/\d{4}/.exec(Date())[0])</script>
</span>
		</div>
		<div class="flex-fill text-end p-0">
			<span class="text-muted">Last updated: December 23, 2024.</span>
		</div>
	</div>
</footer>

    <script src="https://code.jquery.com/jquery-3.3.1.slim.min.js" integrity="sha384-q8i/X+965DzO0rT7abK41JStQIAqVgRVzpbzo5smXKp4YfRvH+8abtTE1Pi6jizo" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js" integrity="sha384-ka7Sk0Gln4gmtz2MlQnikT1wXgYsOg+OMhuP+IlRH9sENBO0LRn5q+8nbTov4+1p" crossorigin="anonymous"></script>
    <script src="/js/copy.js"></script>
    <script>
      $(function () {
      $('[data-toggle="tooltip"]').tooltip({
      animated: 'fade',
      trigger: 'click',
      });
    });
    $("[data-toggle='tooltip']").on('mouseleave', function(){
      setTimeout(function() {   //calls click event after a certain time
       $('[data-toggle="tooltip"]').tooltip('hide');
      }, 1000);
    });
    </script>
  </body>
</html>